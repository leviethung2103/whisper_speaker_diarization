{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b6876d9-9a93-4e07-8b0d-95b397cfdc92",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Speaker Diarization\n",
    "\n",
    "**Installed libraries**\n",
    "- torch\n",
    "- torchvision\n",
    "- tensorflow\n",
    "\n",
    "**Important libraries**\n",
    "- Pyannote Audio\n",
    "- Transfomers\n",
    "- Whisper from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e4d0a4-2cbc-4bd3-bdd0-fe8dce82fa56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers (from -r requirements.txt (line 1))\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-dlituq3u\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-dlituq3u\n",
      "  Resolved https://github.com/huggingface/transformers to commit 2d71307dc0ee2849f785568f345837e726209fc6\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting asteroid-filterbanks>=0.4\n",
      "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
      "Collecting einops>=0.6.0\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m728.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hCollecting huggingface_hub>=0.13.0\n",
      "  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting lightning>=2.0.1\n",
      "  Downloading lightning-2.0.9-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m279.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf<3.0,>=2.1\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m367.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyannote.core>=5.0.0\n",
      "  Downloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m453.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyannote.database>=5.0.1\n",
      "  Downloading pyannote.database-5.0.1-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m573.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyannote.metrics>=3.2\n",
      "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m506.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyannote.pipeline>=2.3\n",
      "  Downloading pyannote.pipeline-2.3-py3-none-any.whl (30 kB)\n",
      "Collecting pytorch_metric_learning>=2.1.0\n",
      "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m765.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rich>=12.0.0\n",
      "  Downloading rich-13.5.3-py3-none-any.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.8/239.8 kB\u001b[0m \u001b[31m782.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting semver>=3.0.0\n",
      "  Downloading semver-3.0.1-py3-none-any.whl (17 kB)\n",
      "Collecting soundfile>=0.12.1\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m392.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting speechbrain>=0.5.14\n",
      "  Downloading speechbrain-0.5.15-py3-none-any.whl (553 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.8/553.8 kB\u001b[0m \u001b[31m633.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboardX>=2.6\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m607.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch_audiomentations>=0.11.0\n",
      "  Downloading torch_audiomentations-0.11.0-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m694.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hCollecting torchmetrics>=0.11.0\n",
      "  Downloading torchmetrics-1.1.2-py3-none-any.whl (764 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.8/764.8 kB\u001b[0m \u001b[31m568.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ffmpeg-python\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting pandas==1.5.0\n",
      "  Downloading pandas-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m859.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers\n",
      "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m314.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm==4.64.1\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m547.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting EasyNMT==2.0.2\n",
      "  Downloading EasyNMT-2.0.2.tar.gz (23 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m159.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pysrt\n",
      "  Downloading pysrt-1.1.2.tar.gz (104 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.4/104.4 kB\u001b[0m \u001b[31m285.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting psutil==5.9.2\n",
      "  Downloading psutil-5.9.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.8/282.8 kB\u001b[0m \u001b[31m175.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 30)) (2.28.2)\n",
      "Collecting faster-whisper\n",
      "  Downloading faster_whisper-0.9.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m116.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.0->-r requirements.txt (line 20)) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.0->-r requirements.txt (line 20)) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.0->-r requirements.txt (line 20)) (2.8.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from EasyNMT==2.0.2->-r requirements.txt (line 25)) (1.13.1+cu116)\n",
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m83.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from EasyNMT==2.0.2->-r requirements.txt (line 25)) (3.19.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0->-r requirements.txt (line 1)) (6.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m771.9/771.9 kB\u001b[0m \u001b[31m72.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0->-r requirements.txt (line 1)) (23.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from asteroid-filterbanks>=0.4->-r requirements.txt (line 2)) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.13.0->-r requirements.txt (line 4)) (2023.3.0)\n",
      "Collecting websockets<13.0\n",
      "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m34.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting deepdiff<8.0,>=5.7.0\n",
      "  Downloading deepdiff-6.5.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.3/71.3 kB\u001b[0m \u001b[31m53.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting inquirer<5.0,>=2.10.0\n",
      "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from lightning>=2.0.1->-r requirements.txt (line 5)) (5.9.0)\n",
      "Collecting fastapi<2.0,>=0.92.0\n",
      "  Downloading fastapi-0.103.1-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m80.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dateutils<2.0\n",
      "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: click<10.0 in /opt/conda/lib/python3.10/site-packages (from lightning>=2.0.1->-r requirements.txt (line 5)) (8.1.3)\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.0.9-py3-none-any.whl (727 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.7/727.7 kB\u001b[0m \u001b[31m67.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Jinja2<5.0 in /opt/conda/lib/python3.10/site-packages (from lightning>=2.0.1->-r requirements.txt (line 5)) (3.1.2)\n",
      "Collecting pydantic<2.2.0,>=1.7.4\n",
      "  Downloading pydantic-2.1.1-py3-none-any.whl (370 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.9/370.9 kB\u001b[0m \u001b[31m42.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting lightning-cloud>=0.5.38\n",
      "  Downloading lightning_cloud-0.5.38-py3-none-any.whl (659 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.0/660.0 kB\u001b[0m \u001b[31m62.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: arrow<3.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from lightning>=2.0.1->-r requirements.txt (line 5)) (1.2.3)\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning>=2.0.1->-r requirements.txt (line 5)) (4.11.2)\n",
      "Collecting croniter<1.5.0,>=1.3.0\n",
      "  Downloading croniter-1.4.1-py2.py3-none-any.whl (19 kB)\n",
      "Collecting uvicorn<2.0\n",
      "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m65.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: websocket-client<3.0 in /opt/conda/lib/python3.10/site-packages (from lightning>=2.0.1->-r requirements.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: urllib3<4.0 in /opt/conda/lib/python3.10/site-packages (from lightning>=2.0.1->-r requirements.txt (line 5)) (1.26.14)\n",
      "Collecting python-multipart<2.0,>=0.0.5\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m52.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting backoff<4.0,>=2.2.1\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting lightning-utilities<2.0,>=0.7.0\n",
      "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
      "Collecting starsessions<2.0,>=1.2.1\n",
      "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting starlette\n",
      "  Downloading starlette-0.31.1-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m44.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m63.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.1 in /opt/conda/lib/python3.10/site-packages (from pyannote.core>=5.0.0->-r requirements.txt (line 7)) (1.10.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from pyannote.core>=5.0.0->-r requirements.txt (line 7)) (2.4.0)\n",
      "Collecting typer[all]>=0.2.1\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m66.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting docopt>=0.6.2\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: sympy>=1.1 in /opt/conda/lib/python3.10/site-packages (from pyannote.metrics>=3.2->-r requirements.txt (line 9)) (1.11.1)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pyannote.metrics>=3.2->-r requirements.txt (line 9)) (3.7.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /opt/conda/lib/python3.10/site-packages (from pyannote.metrics>=3.2->-r requirements.txt (line 9)) (1.2.1)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting optuna>=1.4\n",
      "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m47.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=12.0.0->-r requirements.txt (line 12)) (2.14.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m38.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->-r requirements.txt (line 14)) (1.15.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from speechbrain>=0.5.14->-r requirements.txt (line 15)) (1.2.0)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from speechbrain>=0.5.14->-r requirements.txt (line 15)) (0.13.1+cu116)\n",
      "Collecting hyperpyyaml\n",
      "  Downloading HyperPyYAML-1.2.1-py3-none-any.whl (16 kB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-4.24.3-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m52.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch-pitch-shift>=1.2.2\n",
      "  Downloading torch_pitch_shift-1.2.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting librosa>=0.6.0\n",
      "  Downloading librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m61.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting julius<0.3,>=0.2.3\n",
      "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m54.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting future\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m41.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from sacremoses->-r requirements.txt (line 21)) (1.16.0)\n",
      "Collecting huggingface_hub>=0.13.0\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m50.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m39.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 30)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 30)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 30)) (2022.12.7)\n",
      "Collecting onnxruntime<2,>=1.14\n",
      "  Downloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m28.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0m\n",
      "\u001b[?25hCollecting av==10.*\n",
      "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting ctranslate2<4,>=3.17\n",
      "  Downloading ctranslate2-3.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning>=2.0.1->-r requirements.txt (line 5)) (2.3.2.post1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->-r requirements.txt (line 14)) (2.21)\n",
      "Collecting ordered-set<4.2.0,>=4.0.2\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting anyio<4.0.0,>=3.7.1\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting starlette\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting readchar>=3.0.6\n",
      "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
      "Collecting python-editor>=1.0.4\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting blessed>=1.19.0\n",
      "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<5.0->lightning>=2.0.1->-r requirements.txt (line 5)) (2.1.2)\n",
      "Collecting lazy-loader>=0.1\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.6.0->torch_audiomentations>=0.11.0->-r requirements.txt (line 17)) (1.0.4)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.6.0->torch_audiomentations>=0.11.0->-r requirements.txt (line 17)) (0.56.4)\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading soxr-0.3.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.6.0->torch_audiomentations>=0.11.0->-r requirements.txt (line 17)) (1.7.0)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.6.0->torch_audiomentations>=0.11.0->-r requirements.txt (line 17)) (5.1.1)\n",
      "Requirement already satisfied: pyjwt in /opt/conda/lib/python3.10/site-packages (from lightning-cloud>=0.5.38->lightning>=2.0.1->-r requirements.txt (line 5)) (2.6.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->-r requirements.txt (line 9)) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->-r requirements.txt (line 9)) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->-r requirements.txt (line 9)) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->-r requirements.txt (line 9)) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->-r requirements.txt (line 9)) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->-r requirements.txt (line 9)) (4.38.0)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper->-r requirements.txt (line 31)) (23.3.3)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna>=1.4->pyannote.pipeline>=2.3->-r requirements.txt (line 10)) (2.0.5.post1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna>=1.4->pyannote.pipeline>=2.3->-r requirements.txt (line 10)) (1.10.0)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting cmaes>=0.10.0\n",
      "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
      "Collecting pydantic-core==2.4.0\n",
      "  Downloading pydantic_core-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->-r requirements.txt (line 9)) (3.1.0)\n",
      "Collecting itsdangerous<3.0.0,>=2.0.1\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.1->pyannote.metrics>=3.2->-r requirements.txt (line 9)) (1.2.1)\n",
      "Collecting primePy>=1.3\n",
      "  Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
      "Collecting shellingham<2.0.0,>=1.3.0\n",
      "  Downloading shellingham-1.5.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from typer[all]>=0.2.1->pyannote.database>=5.0.1->-r requirements.txt (line 8)) (0.4.6)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pybind11>=2.2\n",
      "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from fasttext->EasyNMT==2.0.2->-r requirements.txt (line 25)) (67.5.0)\n",
      "Requirement already satisfied: ruamel.yaml<=0.17.28,>=0.17.8 in /opt/conda/lib/python3.10/site-packages (from hyperpyyaml->speechbrain>=0.5.14->-r requirements.txt (line 15)) (0.17.21)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->huggingface_hub>=0.13.0->-r requirements.txt (line 4)) (22.2.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna>=1.4->pyannote.pipeline>=2.3->-r requirements.txt (line 10)) (1.2.4)\n",
      "Collecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi<2.0,>=0.92.0->lightning>=2.0.1->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning>=2.0.1->-r requirements.txt (line 5)) (0.2.6)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa>=0.6.0->torch_audiomentations>=0.11.0->-r requirements.txt (line 17)) (0.39.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa>=0.6.0->torch_audiomentations>=0.11.0->-r requirements.txt (line 17)) (3.1.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /opt/conda/lib/python3.10/site-packages (from ruamel.yaml<=0.17.28,>=0.17.8->hyperpyyaml->speechbrain>=0.5.14->-r requirements.txt (line 15)) (0.2.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna>=1.4->pyannote.pipeline>=2.3->-r requirements.txt (line 10)) (2.0.2)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: EasyNMT, transformers, antlr4-python3-runtime, sacremoses, pysrt, docopt, julius, fasttext, future, audioread\n",
      "  Building wheel for EasyNMT (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for EasyNMT: filename=EasyNMT-2.0.2-py3-none-any.whl size=19903 sha256=b5fbe572f2d109dc906f67739008cc92704161bacc9cfcd959e7216155f6f68f\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/ab/55/72/aba4face7eac1d7750ca700aa1797b135fb8915e949da504cc\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.34.0.dev0-py3-none-any.whl size=7700544 sha256=b42d5270e89f9f17879f2a9ad7544fdbd605feb54d2c6269159e7ee74670cd98\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-l7oeshsj/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=4a70668dd3e16044f11fabadff03df35615763e8ee8d744f319986d94947f4e7\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=531a851c8b7692b0d32f6196b5686f1297ad0bae5c3e47ec27d56df57f76f88e\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
      "  Building wheel for pysrt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pysrt: filename=pysrt-1.1.2-py3-none-any.whl size=13442 sha256=bc8db750f3905dcc816314b7fa5f56611490fbc2fd07b938c2ffa45629025a02\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/30/7f/e8/55de9a9b07302d9e7fe47c27910e3bea0c48536153e74bd7e6\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=6ff231ee55e4a7a1db8ba8a5ed702ca23711da8b1f8dbd9968bfc3e5e1c04584\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "  Building wheel for julius (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21879 sha256=f005a25a44dfc006c8be57dd6ededcec9d0dd4d4d83c142afd59d20ecadc6675\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/b9/b2/05/f883527ffcb7f2ead5438a2c23439aa0c881eaa9a4c80256f4\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=318741 sha256=b6186973375ed2a77263bae4ff37d793dc9b03e3d170f973053c8f32a6741d79\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=d3e085fef49f1ec6f156a75ead1e2f0537d554d0347b008e851b9fdc69989ea1\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/5e/a9/47/f118e66afd12240e4662752cc22cefae5d97275623aa8ef57d\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23704 sha256=61bf06558c3c2430d2cb23a18ca9842002b9b898475b8ce9b1a733808e7441f4\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/da/4b/39/c5f6c4ee93b43281dda4dab5ac5f2bdf9d11074d427493cd55\n",
      "Successfully built EasyNMT transformers antlr4-python3-runtime sacremoses pysrt docopt julius fasttext future audioread\n",
      "Installing collected packages: sentencepiece, safetensors, python-editor, primePy, docopt, av, antlr4-python3-runtime, websockets, typing-extensions, tqdm, tabulate, soxr, shellingham, semver, regex, readchar, python-multipart, pybind11, psutil, protobuf, ordered-set, omegaconf, multidict, mdurl, lazy-loader, itsdangerous, humanfriendly, h11, future, frozenlist, filelock, exceptiongroup, einops, ctranslate2, colorlog, cmaes, chardet, blessed, backoff, audioread, async-timeout, annotated-types, yarl, uvicorn, typer, tensorboardX, soundfile, sacremoses, pysrt, pydantic-core, pyannote.core, pandas, nltk, markdown-it-py, lightning-utilities, inquirer, hyperpyyaml, huggingface_hub, ffmpeg-python, fasttext, deepdiff, dateutils, croniter, coloredlogs, anyio, aiosignal, torchmetrics, tokenizers, starlette, rich, pytorch_metric_learning, pydantic, onnxruntime, librosa, julius, asteroid-filterbanks, aiohttp, transformers, torch-pitch-shift, starsessions, speechbrain, optuna, faster-whisper, fastapi, torch_audiomentations, pytorch-lightning, pyannote.database, lightning-cloud, EasyNMT, pyannote.pipeline, pyannote.metrics, lightning\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.4\n",
      "    Uninstalling psutil-5.9.4:\n",
      "      Successfully uninstalled psutil-5.9.4\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.5.3\n",
      "    Uninstalling pandas-1.5.3:\n",
      "      Successfully uninstalled pandas-1.5.3\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 3.6.2\n",
      "    Uninstalling anyio-3.6.2:\n",
      "      Successfully uninstalled anyio-3.6.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.8.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed EasyNMT-2.0.2 aiohttp-3.8.5 aiosignal-1.3.1 annotated-types-0.5.0 antlr4-python3-runtime-4.9.3 anyio-3.7.1 asteroid-filterbanks-0.4.0 async-timeout-4.0.3 audioread-3.0.0 av-10.0.0 backoff-2.2.1 blessed-1.20.0 chardet-5.2.0 cmaes-0.10.0 coloredlogs-15.0.1 colorlog-6.7.0 croniter-1.4.1 ctranslate2-3.20.0 dateutils-0.6.12 deepdiff-6.5.0 docopt-0.6.2 einops-0.6.1 exceptiongroup-1.1.3 fastapi-0.103.1 faster-whisper-0.9.0 fasttext-0.9.2 ffmpeg-python-0.2.0 filelock-3.12.4 frozenlist-1.4.0 future-0.18.3 h11-0.14.0 huggingface_hub-0.16.4 humanfriendly-10.0 hyperpyyaml-1.2.1 inquirer-3.1.3 itsdangerous-2.1.2 julius-0.2.7 lazy-loader-0.3 librosa-0.10.1 lightning-2.0.9 lightning-cloud-0.5.38 lightning-utilities-0.9.0 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.0.4 nltk-3.8.1 omegaconf-2.3.0 onnxruntime-1.16.0 optuna-3.3.0 ordered-set-4.1.0 pandas-1.5.0 primePy-1.3 protobuf-4.24.3 psutil-5.9.2 pyannote.core-5.0.0 pyannote.database-5.0.1 pyannote.metrics-3.2.1 pyannote.pipeline-2.3 pybind11-2.11.1 pydantic-2.1.1 pydantic-core-2.4.0 pysrt-1.1.2 python-editor-1.0.4 python-multipart-0.0.6 pytorch-lightning-2.0.9 pytorch_metric_learning-2.3.0 readchar-4.0.5 regex-2023.8.8 rich-13.5.3 sacremoses-0.0.53 safetensors-0.3.3 semver-3.0.1 sentencepiece-0.1.99 shellingham-1.5.3 soundfile-0.12.1 soxr-0.3.6 speechbrain-0.5.15 starlette-0.27.0 starsessions-1.3.0 tabulate-0.9.0 tensorboardX-2.6.2.2 tokenizers-0.14.0 torch-pitch-shift-1.2.4 torch_audiomentations-0.11.0 torchmetrics-1.1.2 tqdm-4.64.1 transformers-4.34.0.dev0 typer-0.9.0 typing-extensions-4.8.0 uvicorn-0.23.2 websockets-11.0.3 yarl-1.9.2\n",
      "Collecting protobuf==3.20.*\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.24.3\n",
      "    Uninstalling protobuf-4.24.3:\n",
      "      Successfully uninstalled protobuf-4.24.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.8.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "pyannote-audio 2.1.1 requires torch>=2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\n",
      "pyannote-audio 2.1.1 requires torchaudio>=2.0.0, but you have torchaudio 0.13.1+cu116 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt -q\n",
    "\n",
    "# pynanote audio, whisper requires torch > 2.0, but the Docker image has already torch, tensorflow, torchaudio, torchvision. Therefore, I dont need to install the dependencies while installing the pyannote and transfomer library.\n",
    "!pip install git+https://github.com/pyannote/pyannote-audio --no-deps -q\n",
    "!pip install git+https://github.com/openai/whisper.git --no-deps -q \n",
    "\n",
    "!pip install protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ed0ec8-24af-4aa0-8dd3-d0483bf10337",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai-whisper 20230918 requires more-itertools, which is not installed.\n",
      "openai-whisper 20230918 requires tiktoken, which is not installed.\n",
      "openai-whisper 20230918 requires triton, which is not installed.\n",
      "tensorflow 2.8.2 has requirement protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3.\n",
      "pyannote-audio 2.1.1 has requirement torch>=2.0.0, but you have torch 1.13.1+cu116.\n",
      "pyannote-audio 2.1.1 has requirement torchaudio>=2.0.0, but you have torchaudio 0.13.1+cu116.\n",
      "openai-whisper 20230918 requires more-itertools, which is not installed.\n",
      "openai-whisper 20230918 requires tiktoken, which is not installed.\n",
      "openai-whisper 20230918 requires triton, which is not installed.\n",
      "tensorflow 2.8.2 has requirement protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3.\n",
      "pyannote-audio 2.1.1 has requirement torch>=2.0.0, but you have torch 1.13.1+cu116.\n",
      "pyannote-audio 2.1.1 has requirement torchaudio>=2.0.0, but you have torchaudio 0.13.1+cu116.\n"
     ]
    }
   ],
   "source": [
    "!pip check torchvision\n",
    "!pip check torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedad313-d0a1-4027-a01e-6628c4e2c710",
   "metadata": {},
   "source": [
    "## Download models\n",
    "\n",
    "Whisper model is automatically downloaded from Hugging Face and saved at cache directory\n",
    "\n",
    "`~/.cache/huggingface/hub/models--guillaumekln--faster-whisper-large-v2/`\n",
    "There are four important files:\n",
    "- config.json\n",
    "- model.bin\n",
    "- tokenizer.json\n",
    "- vocabulary.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc278c0-88b8-4094-9a09-ce3e23f768cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "whisper.load_model('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d774d-1fbd-476f-963a-9b851e1f7e53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en', 'zh', 'de', 'ja', 'vi']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850aad033366416488b1bd69dea3a71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02aa5b1c50fe45499d73164679a66fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import whisper\n",
    "from faster_whisper import WhisperModel\n",
    "import datetime\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os \n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import torch\n",
    "import pyannote.audio\n",
    "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\n",
    "from pyannote.audio import Audio\n",
    "from pyannote.core import Segment\n",
    "import wave\n",
    "import contextlib\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "whisper_models = [\"tiny\", \"base\", \"small\", \"medium\", \"large-v1\", \"large-v2\"]\n",
    "source_languages = {\n",
    "    \"en\": \"English\",\n",
    "    \"zh\": \"Chinese\",\n",
    "    \"de\": \"German\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"vi\": \"Vietnamese\"\n",
    "}\n",
    "source_language_list = [key[0] for key in source_languages.items()]\n",
    "\n",
    "print(source_language_list)\n",
    "\n",
    "\n",
    "MODEL_NAME =  \"vumichien/whisper-medium-jp\"\n",
    "lang = \"ja\"\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "# pipeline of transformer\n",
    "pipe = pipeline(\n",
    "    task=\"automatic-speech-recognition\",\n",
    "    model=MODEL_NAME,\n",
    "    chunk_length_s=30,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "\n",
    "os.makedirs('output', exist_ok=True)\n",
    "pipe.model.config.forced_decoder_ids = pipe.tokenizer.get_decoder_prompt_ids(language=lang, task=\"transcribe\")\n",
    "\n",
    "# WHIPSER MODEL\n",
    "whisper_model = 'large-v2'\n",
    "model = WhisperModel(whisper_model, compute_type=\"int8\")\n",
    "\n",
    "# AUDIO FILE \n",
    "video_file_path = \"audio.mp3\"\n",
    "\n",
    "\n",
    "# Read and convert youtube video\n",
    "_,file_ending = os.path.splitext(f'{video_file_path}')\n",
    "print(file_ending)\n",
    "audio_file = video_file_path.replace(file_ending, \".wav\")\n",
    "print(\"audio file:\",audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fbd17d-604d-4314-bf63-3228e8221147",
   "metadata": {},
   "source": [
    "convert mp3 to wav file, measure the duration of audio\n",
    "rate = 16000Hz. tan so lay mau, toc do lay mau. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d18bde8c-392c-493c-9b82-0b46bc39d925",
   "metadata": {},
   "source": [
    "# conversion to wav\n",
    "os.system(f'ffmpeg -i {video_file_path} -ar 16000 -ac 1 -c:a pcm_s16le \"{audio_file}\"')\n",
    "\n",
    "# Get duration\n",
    "with contextlib.closing(wave.open(audio_file,'r')) as f:\n",
    "    frames = f.getnframes()\n",
    "    rate = f.getframerate()\n",
    "    duration = frames / float(rate)\n",
    "    print(\"no of frames\", frames)\n",
    "    print(\"rate\", rate)\n",
    "print(f\"conversion to wav ready, duration of audio file: {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f5f916d-8130-44fe-ad33-845ef0afa673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init = pd.DataFrame(columns=['Start', 'End', 'Speaker', 'Text'])\n",
    "\n",
    "def convert_time(seconds):\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    time_format = \"{:02d}:{:02d}\".format(minutes, seconds)\n",
    "\n",
    "    return time_format\n",
    "\n",
    "def speech_to_text(video_file_path, selected_source_lang, whisper_model, num_speakers):\n",
    "    \"\"\"\n",
    "    # Transcribe youtube link using OpenAI Whisper\n",
    "    1. Using Open AI's Whisper model to seperate audio into segments and generate transcripts.\n",
    "    2. Generating speaker embeddings for each segments.\n",
    "    3. Applying agglomerative clustering on the embeddings to identify the speaker for each segment.\n",
    "    \n",
    "    Speech Recognition is based on models from OpenAI Whisper https://github.com/openai/whisper\n",
    "    Speaker diarization model and pipeline from by https://github.com/pyannote/pyannote-audio\n",
    "    \"\"\"\n",
    "\n",
    "    options = dict(language=selected_source_lang, beam_size=5, best_of=5)\n",
    "    transcribe_options = dict(task=\"transcribe\", **options) \n",
    "    segments_raw, info = model.transcribe(video_file_path, **transcribe_options)\n",
    "    # Convert back to original openai format\n",
    "    segments = []\n",
    "    i = 0\n",
    "    for segment_chunk in segments_raw:\n",
    "        chunk = {}\n",
    "        chunk[\"start\"] = convert_time(segment_chunk.start)\n",
    "        chunk[\"end\"] = convert_time(segment_chunk.end)\n",
    "        chunk[\"text\"] = segment_chunk.text\n",
    "        segments.append(chunk)\n",
    "        i += 1\n",
    "    print(\"transcribe audio done with fast whisper\")\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abbba57-2da6-4777-a257-07c0d22b87bc",
   "metadata": {},
   "source": [
    "## 1.Selected Source Lang = 'ja'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "143cb9a8-ee42-4fb9-a838-a3a350d84236",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcribe audio done with fast whisper\n"
     ]
    }
   ],
   "source": [
    "# Transcribe audio\n",
    "selected_source_lang = 'ja'\n",
    "num_speakers = 4\n",
    "segments = speech_to_text(audio_file, selected_source_lang, whisper_model=model, num_speakers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85e58ed6-514a-48a5-af9d-0209e3f5b727",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': '00:00',\n",
       "  'end': '00:27',\n",
       "  'text': '今日は日本語で来たのさやかとコラボしました 今日はこの会話がどれぐらい聞き取れるかチャレンジしましょう'},\n",
       " {'start': '00:27',\n",
       "  'end': '00:34',\n",
       "  'text': 'これからみなさんに見せる会話は短いバージョンなんですけど 本当の会話は30分あります'},\n",
       " {'start': '00:34',\n",
       "  'end': '00:41',\n",
       "  'text': 'で単語と表現付きの全部の会話動画が見たい人は ぜひサブスクに登録してみてください'},\n",
       " {'start': '00:41', 'end': '00:47', 'text': 'サブスクに登録して一緒にリスニング力と語彙力を高めましょう'},\n",
       " {'start': '00:47', 'end': '00:49', 'text': 'ok じゃあ早速始めましょう'},\n",
       " {'start': '00:49',\n",
       "  'end': '00:53',\n",
       "  'text': 'はいみなさんこんにちは welcome back to my channel'},\n",
       " {'start': '00:53', 'end': '00:56', 'text': '今日はさやかに来てもらいました'},\n",
       " {'start': '00:56', 'end': '00:59', 'text': 'いえーい'},\n",
       " {'start': '00:59', 'end': '01:00', 'text': 'ありがとう'},\n",
       " {'start': '01:00', 'end': '01:03', 'text': 'ありがとう本当に来てくれてありがとう'},\n",
       " {'start': '01:03', 'end': '01:04', 'text': 'こちらこそ'},\n",
       " {'start': '01:04', 'end': '01:08', 'text': '前話した時はたぶん1年前ぐらいかな'},\n",
       " {'start': '01:08', 'end': '01:14', 'text': '1年前に会話動画を一緒に撮ったのが 初めて話した時だったから'},\n",
       " {'start': '01:14', 'end': '01:17', 'text': '約1年ぐらい経ちました'},\n",
       " {'start': '01:17', 'end': '01:21', 'text': 'そうだそうだった'},\n",
       " {'start': '01:21', 'end': '01:24', 'text': 'ね1年前なんだ早いな'},\n",
       " {'start': '01:24', 'end': '01:26', 'text': '早いね'},\n",
       " {'start': '01:26', 'end': '01:30', 'text': 'めっちゃあっという間だった本当にこの1年'},\n",
       " {'start': '01:30', 'end': '01:32', 'text': 'そうだね'},\n",
       " {'start': '01:32',\n",
       "  'end': '01:40',\n",
       "  'text': 'でそれからあのさやかが大阪までわざわざ 新幹線で私に会いに来てくれて'},\n",
       " {'start': '01:40', 'end': '01:44', 'text': '一緒にたこ焼き食べたり'},\n",
       " {'start': '01:44', 'end': '01:46', 'text': '動画撮ったりして'},\n",
       " {'start': '01:46', 'end': '01:50', 'text': 'で私もさやかに名古屋に会いに行って'},\n",
       " {'start': '01:50', 'end': '01:52', 'text': '一緒にねあの名古屋城に行ったり'},\n",
       " {'start': '01:52', 'end': '01:57', 'text': '名古屋城ちょっと閉まってたから入れなかったけど'},\n",
       " {'start': '01:59', 'end': '02:02', 'text': 'まさかの工事中だったけど'},\n",
       " {'start': '02:02', 'end': '02:08', 'text': 'ねすみませんちょっと下調べが足りなかった'},\n",
       " {'start': '02:08', 'end': '02:10', 'text': 'めっちゃ楽しかった本当に'},\n",
       " {'start': '02:10',\n",
       "  'end': '02:20',\n",
       "  'text': 'でえっと今日はさやかと起業家になることのいい点と悪い点について話したいと思います'},\n",
       " {'start': '02:20', 'end': '02:25', 'text': 'はいお願いしますお願いします'},\n",
       " {'start': '02:25', 'end': '02:29', 'text': 'いきなり真面目になった'},\n",
       " {'start': '02:29', 'end': '02:37', 'text': 'さやかも私も自分でビジネスをしていますよね'},\n",
       " {'start': '02:37', 'end': '02:41', 'text': 'で起業家っていうのは英語で'},\n",
       " {'start': '02:41', 'end': '02:45', 'text': 'Entrepreneurかな'},\n",
       " {'start': '02:45', 'end': '02:50', 'text': 'あーその言葉発音するの本当に苦手'},\n",
       " {'start': '02:50', 'end': '02:53', 'text': 'いつもアンチュアアンチュア'},\n",
       " {'start': '02:53', 'end': '02:55', 'text': 'You knowって言っちゃう'},\n",
       " {'start': '02:55', 'end': '02:58', 'text': 'そうそうそうわかる'},\n",
       " {'start': '02:58', 'end': '03:00', 'text': 'ちょっと恥ずかしいよね'},\n",
       " {'start': '03:00', 'end': '03:04', 'text': 'Entrepreneurみたいな'},\n",
       " {'start': '03:05', 'end': '03:10', 'text': 'あのまあみんなに結構周りの人に'},\n",
       " {'start': '03:10', 'end': '03:12', 'text': 'あみくは自分のビジネスがあっていいね'},\n",
       " {'start': '03:12',\n",
       "  'end': '03:18',\n",
       "  'text': '自由に働けていろんなところに行けていいねってよく言われるんだけど'},\n",
       " {'start': '03:18', 'end': '03:22', 'text': 'もちろん本当にありがたいし'},\n",
       " {'start': '03:22', 'end': '03:26', 'text': '本当にこの仕事ができて感謝してるんだけど'},\n",
       " {'start': '03:26', 'end': '03:27', 'text': 'いいことだけじゃなくて'},\n",
       " {'start': '03:27', 'end': '03:32', 'text': '結構大変なこともあるよね'},\n",
       " {'start': '03:32', 'end': '03:36', 'text': 'たくさんあるびっくりする'},\n",
       " {'start': '03:36', 'end': '03:40', 'text': 'びっくりするまだびっくりしてる'},\n",
       " {'start': '03:40', 'end': '03:45', 'text': 'わかるその始める前にはこんなこと考えてなかったから'},\n",
       " {'start': '03:45', 'end': '03:50', 'text': 'ただやりたくて始めたから'},\n",
       " {'start': '03:50', 'end': '03:52', 'text': 'さやかもそうだった'},\n",
       " {'start': '03:52', 'end': '03:53', 'text': '私もそうだった'},\n",
       " {'start': '03:53', 'end': '04:00', 'text': '私はなんかそのビジネスになるっていう構想ができてないのに'},\n",
       " {'start': '04:00', 'end': '04:06', 'text': 'こうインスタグラムで発信し始めて'},\n",
       " {'start': '04:06', 'end': '04:12', 'text': '何か作らないとこれならもっとたくさん助けられると思って'},\n",
       " {'start': '04:12', 'end': '04:18', 'text': '日本語学びたい人助けられると思って始めたから'},\n",
       " {'start': '04:18', 'end': '04:23', 'text': 'ビジネスの仕方が全くわからなかった'},\n",
       " {'start': '04:23', 'end': '04:25', 'text': 'そう全く同じ'},\n",
       " {'start': '04:25', 'end': '04:29', 'text': 'だってインスタグラムであの紙とペンで教えてる時に'},\n",
       " {'start': '04:29',\n",
       "  'end': '04:36',\n",
       "  'text': 'まさか自分が日本語をyoutubeで教えるなんて思ってなかったし'},\n",
       " {'start': '04:36', 'end': '04:41', 'text': 'これがビジネスになるなんて1ミリも思ってなかったから'},\n",
       " {'start': '04:41', 'end': '04:45', 'text': '何も考えずに始めた'},\n",
       " {'start': '04:45', 'end': '04:47', 'text': 'うんもう本当に同じそれは'},\n",
       " {'start': '04:47', 'end': '04:49', 'text': 'そのビジネスオーナーをしてて'},\n",
       " {'start': '04:49', 'end': '04:54', 'text': 'いい点はどんなところ'},\n",
       " {'start': '04:54', 'end': '05:01', 'text': 'いい点は何でも自分次第なところ'},\n",
       " {'start': '05:01', 'end': '05:06', 'text': '頑張れば頑張っただけ結果がついてくるし'},\n",
       " {'start': '05:06', 'end': '05:14', 'text': 'サボればサボっただけの結果になるっていうところが一つ'},\n",
       " {'start': '05:14', 'end': '05:19', 'text': '2点目は時間かな'},\n",
       " {'start': '05:19', 'end': '05:23', 'text': '時間が自由に使える'},\n",
       " {'start': '05:23',\n",
       "  'end': '05:29',\n",
       "  'text': 'なんだろうちょっとこの2時間は昼休憩しようって思ったら休憩できる'},\n",
       " {'start': '05:29', 'end': '05:32', 'text': 'それはいいかな'},\n",
       " {'start': '05:32', 'end': '05:36', 'text': '本当にそれは私も同じかな'},\n",
       " {'start': '05:36', 'end': '05:38', 'text': 'それ私もリストに入れた'},\n",
       " {'start': '05:38', 'end': '05:41', 'text': '大切な人との時間を優先できるって書いた'},\n",
       " {'start': '05:41', 'end': '05:47', 'text': 'あとさやかが言った一つ目のこと'},\n",
       " {'start': '05:47', 'end': '05:54', 'text': 'そう自分で何でも決められるっていうところは本当にいいと思う'},\n",
       " {'start': '05:54',\n",
       "  'end': '06:01',\n",
       "  'text': '特に日本ってマニュアル通りにしなきゃいけないっていうのが結構強いから'},\n",
       " {'start': '06:01',\n",
       "  'end': '06:07',\n",
       "  'text': '自分が例えばこうしたらもっと良くなるんじゃないかなっていう意見があったとしても'},\n",
       " {'start': '06:07', 'end': '06:12', 'text': 'それを押し殺さないといけないじゃん'},\n",
       " {'start': '06:12', 'end': '06:18', 'text': 'それが私の性格に全然あってなくて'},\n",
       " {'start': '06:18',\n",
       "  'end': '06:30',\n",
       "  'text': 'なるほどなんか自分が日本で正社員になって働いている姿が全然想像できなくて'},\n",
       " {'start': '06:30', 'end': '06:39', 'text': '私もちょうどアメリカに留学に行って帰ってきたのが大学3年生の時'},\n",
       " {'start': '06:39',\n",
       "  'end': '06:47',\n",
       "  'text': 'でその時は絶対卒業したらアメリカに戻って向こうで働くって思ってたから'},\n",
       " {'start': '06:47', 'end': '06:51', 'text': 'なんか正社員になったら辞めづらいし'},\n",
       " {'start': '06:51', 'end': '06:56', 'text': 'だったら早くパパパッとお金稼いで向こうで働きたい'},\n",
       " {'start': '06:56', 'end': '07:01', 'text': '向こうに行って働きたいと思って'},\n",
       " {'start': '07:01', 'end': '07:07', 'text': 'なんかもうちょっとオープンなリラックスした働き方がしたくて'},\n",
       " {'start': '07:07', 'end': '07:11', 'text': 'そうだよね'},\n",
       " {'start': '07:11', 'end': '07:19', 'text': 'だからその自分一人でやってるともちろん大変なこともあるけど'},\n",
       " {'start': '07:19', 'end': '07:26', 'text': '自分が考えたアイディアがそのまま形にできる'},\n",
       " {'start': '07:26', 'end': '07:31', 'text': '日本だったら自分が考えたことをまず上司に聞いて'},\n",
       " {'start': '07:31', 'end': '07:35', 'text': 'こういうことをしたいと思うんですけどどうですかって聞いて'},\n",
       " {'start': '07:35', 'end': '07:39', 'text': 'でも上司がダメって言ったらもうそこで終わりじゃん'},\n",
       " {'start': '07:39', 'end': '07:45', 'text': 'そうだねほとんどの日本の企業はそうなのかなって思うけど'},\n",
       " {'start': '07:45', 'end': '07:49', 'text': 'どうなんだろうね新しい会社とかは違うのかな'},\n",
       " {'start': '07:49', 'end': '07:57', 'text': '外資系とか海外の会社だったら違うと思うけど'},\n",
       " {'start': '07:57', 'end': '08:05', 'text': 'やっぱり保守的新しいことを取り入れないから日本の企業って'},\n",
       " {'start': '08:05', 'end': '08:16', 'text': 'そこに身を置くと成長できないし多分満足できないと思う'},\n",
       " {'start': '08:16', 'end': '08:17', 'text': 'わかる'},\n",
       " {'start': '08:17', 'end': '08:20', 'text': 'はいみなさんどれぐらい聞き取れましたか'},\n",
       " {'start': '08:20', 'end': '08:24', 'text': '最初に言ったようにもっと長い会話の動画が見たい人や'},\n",
       " {'start': '08:24', 'end': '08:29', 'text': '会話でよく使える単語や表現が学びたい人は'},\n",
       " {'start': '08:29', 'end': '08:31', 'text': 'ぜひサブスクに登録してください'},\n",
       " {'start': '08:31', 'end': '08:34', 'text': 'ふりがな付きの日本語トランスクリプトがもらえるので'},\n",
       " {'start': '08:34', 'end': '08:40', 'text': 'まだ初級で全部聞き取れない人や漢字が読めない人でも大丈夫です'},\n",
       " {'start': '08:40', 'end': '08:44', 'text': 'もっと日本人が実際に使う日本語を学びたい人や'},\n",
       " {'start': '08:44', 'end': '08:49', 'text': '自然な会話ができるようになりたい人はぜひ登録してみてください'},\n",
       " {'start': '08:49',\n",
       "  'end': '08:54',\n",
       "  'text': 'あと7ドルサポーターになると私の限定youtubeライブにも参加できます'},\n",
       " {'start': '08:54',\n",
       "  'end': '08:59',\n",
       "  'text': 'もっと日本語が聞きたい人や私や参加者のみんなとおしゃべりしたい人は'},\n",
       " {'start': '08:59', 'end': '09:01', 'text': 'ぜひ参加してみてください'},\n",
       " {'start': '09:01', 'end': '09:04', 'text': 'あと日本語のリスニングはできるけど'},\n",
       " {'start': '09:04', 'end': '09:08', 'text': '頭の中で文を作るのに時間がかかってしまう人や'},\n",
       " {'start': '09:08', 'end': '09:10', 'text': 'スピーキングに自信がない人は'},\n",
       " {'start': '09:10', 'end': '09:14', 'text': 'ぜひ私のシャドーイングコースも試してみてください'},\n",
       " {'start': '09:14', 'end': '09:17', 'text': 'サンプルオーディオが無料で聞けるので'},\n",
       " {'start': '09:17', 'end': '09:19', 'text': 'もし興味があったら聞いてみてください'},\n",
       " {'start': '09:19', 'end': '09:21', 'text': 'リンクは下に貼ってあります'},\n",
       " {'start': '09:21',\n",
       "  'end': '09:26',\n",
       "  'text': '今まで5000人以上の人が私のコースで日本語を勉強してくれました'},\n",
       " {'start': '09:26', 'end': '09:31', 'text': 'たくさんの人がもっと自信を持って日本語が話せるようになった'},\n",
       " {'start': '09:31', 'end': '09:32', 'text': '語彙力が伸びた'},\n",
       " {'start': '09:32',\n",
       "  'end': '09:38',\n",
       "  'text': '日本人の先生や友達に発音が良くなったと言われたと言ってくれました'},\n",
       " {'start': '09:38', 'end': '09:42', 'text': '仕事や子育てで日本語の勉強をする時間がない人も'},\n",
       " {'start': '09:42', 'end': '09:45', 'text': '通勤しながらとか家事をしながら'},\n",
       " {'start': '09:45', 'end': '09:48', 'text': '私のコースで日本語を勉強してくれました'},\n",
       " {'start': '09:51',\n",
       "  'end': '09:55',\n",
       "  'text': 'このビデオを見てくださった皆さんのプロダクトを楽しんでいただけたら嬉しいです'},\n",
       " {'start': '09:55', 'end': '09:57', 'text': '特にシャドーイングオーディオを使ってもらった方が良いです'},\n",
       " {'start': '09:57', 'end': '10:00', 'text': '私の仕事は旅行や車でたくさんの時間を使っているので'},\n",
       " {'start': '10:00', 'end': '10:04', 'text': '仕事に行く時はシャドーイングオーディオをスピーカーに入れて'},\n",
       " {'start': '10:04', 'end': '10:07', 'text': '仕事に行っても同時に日本語を勉強することができます'},\n",
       " {'start': '10:07', 'end': '10:10', 'text': 'とても便利でとても便利です'},\n",
       " {'start': '10:10', 'end': '10:12', 'text': '日本語を勉強したくない人は'},\n",
       " {'start': '10:12',\n",
       "  'end': '10:20',\n",
       "  'text': '休憩や楽しみながら日本語を勉強しながら日本語を勉強することをお勧めします'},\n",
       " {'start': '10:20', 'end': '10:30', 'text': 'ミク先生の素晴らしい仕事を毎回作ってくれて本当に感謝しています'},\n",
       " {'start': '10:30', 'end': '10:34', 'text': '最初は大学で日本語を勉強し始めました'},\n",
       " {'start': '10:34', 'end': '10:38', 'text': '数年後に実は日本に行きました'},\n",
       " {'start': '10:38', 'end': '10:41', 'text': 'そこで1年間日本語を勉強しました'},\n",
       " {'start': '10:41', 'end': '10:47', 'text': '日本語の授業ではなく自然的な日本語を勉強したいと思いました'},\n",
       " {'start': '10:47', 'end': '10:52', 'text': 'ミク先生の授業はそのために本当に完璧です'},\n",
       " {'start': '10:52', 'end': '10:54', 'text': 'これが最高の解決策です'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbb66b3c-4d98-434c-bbf4-19d17b4fc127",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcribe audio done with fast whisper\n"
     ]
    }
   ],
   "source": [
    "# Transcribe audio\n",
    "selected_source_lang = 'en'\n",
    "num_speakers = 4\n",
    "segments = speech_to_text(audio_file, selected_source_lang, whisper_model=model, num_speakers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fb4d1-42ea-4755-931c-7af724065957",
   "metadata": {},
   "source": [
    "## Lesson Learned\n",
    "\n",
    "- You should choose Japanese language because most of time, speakers were talking in Japanese.\n",
    "- Even though there is an English part in the audio (time segment at minute 10:20 onwards), the program automatically translates it into Japanes -> It's quite good. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
